{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from torchimize.functions import lsq_lma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "# For data preprocessing. To be replcaed with AR section.\n",
    "cancer_data = pd.read_csv('/Users/waldo/Documents/23 HT/Data Mining 1DL370/Assignment4/cancer.csv',sep=';')\n",
    "cancer_data.iloc[cancer_data['diagnosis'] == 'M',1] = 1\n",
    "cancer_data.iloc[cancer_data['diagnosis'] == 'B',1] = 0\n",
    "cancer_benign = cancer_data[cancer_data['diagnosis'] == 0]\n",
    "\n",
    "X, y = cancer_data.iloc[:,2:], cancer_data.iloc[:,1]\n",
    "X_normed = pd.DataFrame(MinMaxScaler().fit_transform(X))\n",
    "X = X_normed.astype('float')\n",
    "y = y.astype('float')\n",
    "X = X.values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=0)\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).to(device)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test.to_numpy(), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([455, 32])\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.input_layer = nn.Linear(32, 11)  # 32 input neurons to 11 hidden neurons. This will be changed to actual number of features.\n",
    "        self.hidden_layer = nn.Linear(11, 1)  # 11 hidden neurons to 1 output neuron\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.tanh(self.input_layer(x))  # Apply tanh activation to the input layer\n",
    "        x = torch.sigmoid(self.hidden_layer(x))  # Apply sigmoid activation to the output layer for binary classification\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = MLP()\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "#for name, param in model.named_parameters():\n",
    "    #print(name, param)\n",
    "\n",
    "# Define the optimizer (Adam optimizer). To be changed to Lev-Mar\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 44\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs, y_train.view(-1, 1))\n",
    "    #print(loss)\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()  # Update weights\n",
    "    \n",
    "    #if (epoch + 1) % 1000 == 0:\n",
    "       # print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "print(\"Training completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data: 0.9737\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    predictions = model(X_test)\n",
    "    predictions = (predictions > 0.5).float()\n",
    "    accuracy = torch.sum(predictions.view(-1) == y_test).item() / y_test.size(0)\n",
    "    print(f'Accuracy on test data: {accuracy:.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nloss_list = []\\n\\nclass LevenbergMarquardtOptimizer:\\n    def __init__(self, model, target_func, initial_params, lambda_=0.01, max_iterations=50):\\n        self.model = model\\n        self.target_func = target_func\\n        self.params = torch.nn.Parameter(torch.tensor(initial_params, requires_grad=True))\\n        self.lambda_ = lambda_\\n        self.max_iterations = max_iterations\\n\\n    def optimize(self):\\n        optimizer = torch.optim.SGD([self.params], lr=0.01)  # Dummy optimizer, as we manually perform updates\\n        \\n        for iteration in range(self.max_iterations):\\n            optimizer.zero_grad()\\n            loss = self.target_func(self.model(self.params))\\n            loss_list.append(loss)\\n            print(loss)\\n            loss.backward()\\n\\n            # Compute the approximate Hessian matrix\\n            with torch.no_grad():\\n                approx_hessian = torch.autograd.functional.hessian(self.target_func, self.params)\\n                diag_values = approx_hessian.diagonal() + self.lambda_\\n            # Update parameters using LM formula: theta_new = theta - (H + lambda*I)^(-1) * gradient\\n            update = torch.linalg.solve(approx_hessian + torch.diag(diag_values), -self.params.grad)\\n            self.params.data += update\\n\\n        return self.params.data.numpy()\\n\\n# Example usage:\\n\\n# Define your target function and model appropriately\\ndef target_func(output):\\n    # Define your loss function here, for example, mean squared error\\n    loss = torch.mean((output - y_train.view(-1, 1))**2)\\n    return loss\\n\\n# Instantiate your model and Levenberg-Marquardt optimizer\\nmodel = MLP()\\ninitial_params = torch.empty(X_train.shape[1])\\ninitial_params = nn.init.uniform_(initial_params)\\n#initial_params = torch.tensor([1.0] * 375)  # Initial guess for parameters\\nlm_optimizer = LevenbergMarquardtOptimizer(model, target_func, model.parameters())\\n\\n# Perform optimization\\noptimized_params = lm_optimizer.optimize()\\n'"
      ]
     },
     "execution_count": 851,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "loss_list = []\n",
    "\n",
    "class LevenbergMarquardtOptimizer:\n",
    "    def __init__(self, model, target_func, initial_params, lambda_=0.01, max_iterations=50):\n",
    "        self.model = model\n",
    "        self.target_func = target_func\n",
    "        self.params = torch.nn.Parameter(torch.tensor(initial_params, requires_grad=True))\n",
    "        self.lambda_ = lambda_\n",
    "        self.max_iterations = max_iterations\n",
    "\n",
    "    def optimize(self):\n",
    "        optimizer = torch.optim.SGD([self.params], lr=0.01)  # Dummy optimizer, as we manually perform updates\n",
    "        \n",
    "        for iteration in range(self.max_iterations):\n",
    "            optimizer.zero_grad()\n",
    "            loss = self.target_func(self.model(self.params))\n",
    "            loss_list.append(loss)\n",
    "            print(loss)\n",
    "            loss.backward()\n",
    "\n",
    "            # Compute the approximate Hessian matrix\n",
    "            with torch.no_grad():\n",
    "                approx_hessian = torch.autograd.functional.hessian(self.target_func, self.params)\n",
    "                diag_values = approx_hessian.diagonal() + self.lambda_\n",
    "            # Update parameters using LM formula: theta_new = theta - (H + lambda*I)^(-1) * gradient\n",
    "            update = torch.linalg.solve(approx_hessian + torch.diag(diag_values), -self.params.grad)\n",
    "            self.params.data += update\n",
    "\n",
    "        return self.params.data.numpy()\n",
    "\n",
    "# Example usage:\n",
    "\n",
    "# Define your target function and model appropriately\n",
    "def target_func(output):\n",
    "    # Define your loss function here, for example, mean squared error\n",
    "    loss = torch.mean((output - y_train.view(-1, 1))**2)\n",
    "    return loss\n",
    "\n",
    "# Instantiate your model and Levenberg-Marquardt optimizer\n",
    "model = MLP()\n",
    "initial_params = torch.empty(X_train.shape[1])\n",
    "initial_params = nn.init.uniform_(initial_params)\n",
    "#initial_params = torch.tensor([1.0] * 375)  # Initial guess for parameters\n",
    "lm_optimizer = LevenbergMarquardtOptimizer(model, target_func, model.parameters())\n",
    "\n",
    "# Perform optimization\n",
    "optimized_params = lm_optimizer.optimize()\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200], Loss: 0.2608\n",
      "Epoch [11/200], Loss: 0.2030\n",
      "Epoch [21/200], Loss: 0.1426\n",
      "Epoch [31/200], Loss: 0.0940\n",
      "Epoch [41/200], Loss: 0.0702\n",
      "Epoch [51/200], Loss: 0.0581\n",
      "Epoch [61/200], Loss: 0.0509\n",
      "Epoch [71/200], Loss: 0.0461\n",
      "Epoch [81/200], Loss: 0.0425\n",
      "Epoch [91/200], Loss: 0.0397\n",
      "Epoch [101/200], Loss: 0.0375\n",
      "Epoch [111/200], Loss: 0.0356\n",
      "Epoch [121/200], Loss: 0.0340\n",
      "Epoch [131/200], Loss: 0.0327\n",
      "Epoch [141/200], Loss: 0.0315\n",
      "Epoch [151/200], Loss: 0.0304\n",
      "Epoch [161/200], Loss: 0.0294\n",
      "Epoch [171/200], Loss: 0.0286\n",
      "Epoch [181/200], Loss: 0.0278\n",
      "Epoch [191/200], Loss: 0.0271\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Optimizer\n",
    "\n",
    "\n",
    "def target_func(output):\n",
    "    return criterion(outputs, y_train.view(-1, 1))\n",
    "\n",
    "class LevenbergMarquardt(Optimizer):\n",
    "    def __init__(self, params, lr=1, lambda_=0.01):\n",
    "        if lr < 0.0:\n",
    "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
    "        if lambda_ < 0.0:\n",
    "            raise ValueError(\"Invalid lambda value: {}\".format(lambda_))\n",
    "        \n",
    "        defaults = dict(lr=lr, lambda_=lambda_)\n",
    "        super(LevenbergMarquardt, self).__init__(params, defaults)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            with torch.enable_grad():\n",
    "                loss = closure()\n",
    "                \n",
    "        for group in self.param_groups:\n",
    "            for param in group['params']:\n",
    "                if param.grad is None:\n",
    "                    continue\n",
    "\n",
    "                lr = group['lr']\n",
    "                lambda_ = group['lambda_']\n",
    "                if len(param.shape) == 2:\n",
    "                    d_p = param.grad\n",
    "                    d_p = torch.reshape(d_p, (-1,))\n",
    "                    shape0, shape1 = param.shape[0],param.shape[1]\n",
    "                    param = torch.reshape(param, (-1,))\n",
    "                    # Compute the approximate Hessian matrix (second derivative)\n",
    "                    approx_hessian = torch.autograd.functional.hessian(func=target_func,inputs=param,create_graph=True)\n",
    "                    diag_values = torch.diag(approx_hessian) + lambda_\n",
    "                    # Update parameters using LM formula: theta_new = theta - (H + lambda*I)^(-1) * gradient\n",
    "                    update = torch.linalg.solve(approx_hessian + torch.diag(diag_values), -d_p)\n",
    "                    param.data += lr * update\n",
    "                    param = torch.reshape(param,(shape0,shape1))\n",
    "                else:\n",
    "                    d_p = param.grad\n",
    "                    approx_hessian = torch.autograd.functional.hessian(func=target_func,inputs=param,create_graph=True)\n",
    "                    diag_values = torch.diag(approx_hessian) + lambda_\n",
    "                    # Update parameters using LM formula: theta_new = theta - (H + lambda*I)^(-1) * gradient\n",
    "                    update = torch.linalg.solve(approx_hessian + torch.diag(diag_values), -d_p)\n",
    "                    param.data += lr * update\n",
    "\n",
    "        return loss\n",
    "\n",
    "model = MLP()\n",
    "lm_optimizer = LevenbergMarquardt(model.parameters(), lr=0.001, lambda_=0.001)\n",
    "loss_list = []\n",
    "num_epochs = 200\n",
    "for epoch in range(num_epochs):\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs, y_train.view(-1, 1))      \n",
    "    loss_list.append(loss.item())  \n",
    "    lm_optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    lm_optimizer.step()\n",
    "    if epoch%10 == 0:\n",
    "        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 853,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data: 0.9649\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    predictions = model(X_test)\n",
    "    predictions = (predictions > 0.5).float()\n",
    "    accuracy = torch.sum(predictions.view(-1) == y_test).item() / y_test.size(0)\n",
    "    print(f'Accuracy on test data: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 854,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.linspace(1, len(loss_list) ,len(loss_list))\n",
    "y = loss_list\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(x, y, label='loss', color='m', linewidth=1.5)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Loss Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1c612fed8d120ac5c30643c808a4d3b681130bd8cc40d3014416815b15cd817e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
