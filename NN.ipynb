{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 912,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from torchimize.functions import lsq_lma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 913,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 32)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "# For data preprocessing. To be replcaed with AR section.\n",
    "cancer_data = pd.read_csv('/Users/waldo/Documents/23 HT/Data Mining 1DL370/Assignment4/cancer.csv',sep=';')\n",
    "cancer_data.iloc[cancer_data['diagnosis'] == 'M',1] = 1\n",
    "cancer_data.iloc[cancer_data['diagnosis'] == 'B',1] = 0\n",
    "cancer_benign = cancer_data[cancer_data['diagnosis'] == 0]\n",
    "\n",
    "X, y = cancer_data.iloc[:,2:], cancer_data.iloc[:,1]\n",
    "X_normed = pd.DataFrame(MinMaxScaler().fit_transform(X))\n",
    "X = X_normed.astype('float')\n",
    "y = y.astype('float')\n",
    "X = X.values\n",
    "print(X.shape)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.398, random_state=0)\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).to(device)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test.to_numpy(), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 914,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([342, 32])\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 915,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.input_layer = nn.Linear(32, 11)  # 32 input neurons to 11 hidden neurons. This will be changed to actual number of features.\n",
    "        self.hidden_layer = nn.Linear(11, 1)  # 11 hidden neurons to 1 output neuron\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.tanh(self.input_layer(x))  # Apply tanh activation to the input layer\n",
    "        x = torch.sigmoid(self.hidden_layer(x))  # Apply sigmoid activation to the output layer for binary classification\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 916,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = MLP()\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "#for name, param in model.named_parameters():\n",
    "    #print(name, param)\n",
    "\n",
    "# Define the optimizer (Adam optimizer). To be changed to Lev-Mar\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 917,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 44\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs, y_train.view(-1, 1))\n",
    "    #print(loss)\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()  # Update weights\n",
    "    \n",
    "    #if (epoch + 1) % 1000 == 0:\n",
    "       # print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "print(\"Training completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 918,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data: 0.9780\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    predictions = model(X_test)\n",
    "    predictions = (predictions > 0.5).float()\n",
    "    accuracy = torch.sum(predictions.view(-1) == y_test).item() / y_test.size(0)\n",
    "    print(f'Accuracy on test data: {accuracy:.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 919,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nloss_list = []\\n\\nclass LevenbergMarquardtOptimizer:\\n    def __init__(self, model, target_func, initial_params, lambda_=0.01, max_iterations=50):\\n        self.model = model\\n        self.target_func = target_func\\n        self.params = torch.nn.Parameter(torch.tensor(initial_params, requires_grad=True))\\n        self.lambda_ = lambda_\\n        self.max_iterations = max_iterations\\n\\n    def optimize(self):\\n        optimizer = torch.optim.SGD([self.params], lr=0.01)  # Dummy optimizer, as we manually perform updates\\n        \\n        for iteration in range(self.max_iterations):\\n            optimizer.zero_grad()\\n            loss = self.target_func(self.model(self.params))\\n            loss_list.append(loss)\\n            print(loss)\\n            loss.backward()\\n\\n            # Compute the approximate Hessian matrix\\n            with torch.no_grad():\\n                approx_hessian = torch.autograd.functional.hessian(self.target_func, self.params)\\n                diag_values = approx_hessian.diagonal() + self.lambda_\\n            # Update parameters using LM formula: theta_new = theta - (H + lambda*I)^(-1) * gradient\\n            update = torch.linalg.solve(approx_hessian + torch.diag(diag_values), -self.params.grad)\\n            self.params.data += update\\n\\n        return self.params.data.numpy()\\n\\n# Example usage:\\n\\n# Define your target function and model appropriately\\ndef target_func(output):\\n    # Define your loss function here, for example, mean squared error\\n    loss = torch.mean((output - y_train.view(-1, 1))**2)\\n    return loss\\n\\n# Instantiate your model and Levenberg-Marquardt optimizer\\nmodel = MLP()\\ninitial_params = torch.empty(X_train.shape[1])\\ninitial_params = nn.init.uniform_(initial_params)\\n#initial_params = torch.tensor([1.0] * 375)  # Initial guess for parameters\\nlm_optimizer = LevenbergMarquardtOptimizer(model, target_func, model.parameters())\\n\\n# Perform optimization\\noptimized_params = lm_optimizer.optimize()\\n'"
      ]
     },
     "execution_count": 919,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "loss_list = []\n",
    "\n",
    "class LevenbergMarquardtOptimizer:\n",
    "    def __init__(self, model, target_func, initial_params, lambda_=0.01, max_iterations=50):\n",
    "        self.model = model\n",
    "        self.target_func = target_func\n",
    "        self.params = torch.nn.Parameter(torch.tensor(initial_params, requires_grad=True))\n",
    "        self.lambda_ = lambda_\n",
    "        self.max_iterations = max_iterations\n",
    "\n",
    "    def optimize(self):\n",
    "        optimizer = torch.optim.SGD([self.params], lr=0.01)  # Dummy optimizer, as we manually perform updates\n",
    "        \n",
    "        for iteration in range(self.max_iterations):\n",
    "            optimizer.zero_grad()\n",
    "            loss = self.target_func(self.model(self.params))\n",
    "            loss_list.append(loss)\n",
    "            print(loss)\n",
    "            loss.backward()\n",
    "\n",
    "            # Compute the approximate Hessian matrix\n",
    "            with torch.no_grad():\n",
    "                approx_hessian = torch.autograd.functional.hessian(self.target_func, self.params)\n",
    "                diag_values = approx_hessian.diagonal() + self.lambda_\n",
    "            # Update parameters using LM formula: theta_new = theta - (H + lambda*I)^(-1) * gradient\n",
    "            update = torch.linalg.solve(approx_hessian + torch.diag(diag_values), -self.params.grad)\n",
    "            self.params.data += update\n",
    "\n",
    "        return self.params.data.numpy()\n",
    "\n",
    "# Example usage:\n",
    "\n",
    "# Define your target function and model appropriately\n",
    "def target_func(output):\n",
    "    # Define your loss function here, for example, mean squared error\n",
    "    loss = torch.mean((output - y_train.view(-1, 1))**2)\n",
    "    return loss\n",
    "\n",
    "# Instantiate your model and Levenberg-Marquardt optimizer\n",
    "model = MLP()\n",
    "initial_params = torch.empty(X_train.shape[1])\n",
    "initial_params = nn.init.uniform_(initial_params)\n",
    "#initial_params = torch.tensor([1.0] * 375)  # Initial guess for parameters\n",
    "lm_optimizer = LevenbergMarquardtOptimizer(model, target_func, model.parameters())\n",
    "\n",
    "# Perform optimization\n",
    "optimized_params = lm_optimizer.optimize()\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 920,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200], Loss: 0.2631\n",
      "Epoch [11/200], Loss: 0.2290\n",
      "Epoch [21/200], Loss: 0.1796\n",
      "Epoch [31/200], Loss: 0.1153\n",
      "Epoch [41/200], Loss: 0.0786\n",
      "Epoch [51/200], Loss: 0.0614\n",
      "Epoch [61/200], Loss: 0.0521\n",
      "Epoch [71/200], Loss: 0.0462\n",
      "Epoch [81/200], Loss: 0.0422\n",
      "Epoch [91/200], Loss: 0.0391\n",
      "Epoch [101/200], Loss: 0.0367\n",
      "Epoch [111/200], Loss: 0.0347\n",
      "Epoch [121/200], Loss: 0.0331\n",
      "Epoch [131/200], Loss: 0.0317\n",
      "Epoch [141/200], Loss: 0.0305\n",
      "Epoch [151/200], Loss: 0.0294\n",
      "Epoch [161/200], Loss: 0.0285\n",
      "Epoch [171/200], Loss: 0.0277\n",
      "Epoch [181/200], Loss: 0.0269\n",
      "Epoch [191/200], Loss: 0.0263\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Optimizer\n",
    "\n",
    "\n",
    "def target_func(output):\n",
    "    return criterion(outputs, y_train.view(-1, 1))\n",
    "\n",
    "class LevenbergMarquardt(Optimizer):\n",
    "    def __init__(self, params, lr=1, lambda_=0.01):\n",
    "        if lr < 0.0:\n",
    "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
    "        if lambda_ < 0.0:\n",
    "            raise ValueError(\"Invalid lambda value: {}\".format(lambda_))\n",
    "        \n",
    "        defaults = dict(lr=lr, lambda_=lambda_)\n",
    "        super(LevenbergMarquardt, self).__init__(params, defaults)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            with torch.enable_grad():\n",
    "                loss = closure()\n",
    "                \n",
    "        for group in self.param_groups:\n",
    "            for param in group['params']:\n",
    "                if param.grad is None:\n",
    "                    continue\n",
    "\n",
    "                lr = group['lr']\n",
    "                lambda_ = group['lambda_']\n",
    "                if len(param.shape) == 2:\n",
    "                    d_p = param.grad\n",
    "                    d_p = torch.reshape(d_p, (-1,))\n",
    "                    shape0, shape1 = param.shape[0],param.shape[1]\n",
    "                    param = torch.reshape(param, (-1,))\n",
    "                    # Compute the approximate Hessian matrix (second derivative)\n",
    "                    approx_hessian = torch.autograd.functional.hessian(func=target_func,inputs=param,create_graph=True)\n",
    "                    diag_values = torch.diag(approx_hessian) + lambda_\n",
    "                    # Update parameters using LM formula: theta_new = theta - (H + lambda*I)^(-1) * gradient\n",
    "                    update = torch.linalg.solve(approx_hessian + torch.diag(diag_values), -d_p)\n",
    "                    param.data += lr * update\n",
    "                    param = torch.reshape(param,(shape0,shape1))\n",
    "                else:\n",
    "                    d_p = param.grad\n",
    "                    approx_hessian = torch.autograd.functional.hessian(func=target_func,inputs=param,create_graph=True)\n",
    "                    diag_values = torch.diag(approx_hessian) + lambda_\n",
    "                    # Update parameters using LM formula: theta_new = theta - (H + lambda*I)^(-1) * gradient\n",
    "                    update = torch.linalg.solve(approx_hessian + torch.diag(diag_values), -d_p)\n",
    "                    param.data += lr * update\n",
    "\n",
    "        return loss\n",
    "\n",
    "model = MLP()\n",
    "lm_optimizer = LevenbergMarquardt(model.parameters(), lr=0.001, lambda_=0.001)\n",
    "loss_list = []\n",
    "num_epochs = 200\n",
    "for epoch in range(num_epochs):\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs, y_train.view(-1, 1))      \n",
    "    loss_list.append(loss.item())  \n",
    "    lm_optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    lm_optimizer.step()\n",
    "    if epoch%10 == 0:\n",
    "        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 921,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data: 0.9604\n",
      "Correct: 218 Incorrect 9\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    predictions = model(X_test)\n",
    "    predictions = (predictions > 0.5).float()\n",
    "    accuracy = torch.sum(predictions.view(-1) == y_test).item() / y_test.size(0)\n",
    "    print(f'Accuracy on test data: {accuracy:.4f}')\n",
    "    print('Correct:',torch.sum(predictions.view(-1) == y_test).item(),\"Incorrect\",y_test.size(0)-torch.sum(predictions.view(-1) == y_test).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 922,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.linspace(1, len(loss_list) ,len(loss_list))\n",
    "y = loss_list\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(x, y, label='loss', color='m', linewidth=1.5)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Loss Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1c612fed8d120ac5c30643c808a4d3b681130bd8cc40d3014416815b15cd817e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
